{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net: Convolutional Networks for Biomedical Image Segmentation \n",
    "### Olaf Ronneberger, Philipp Fischer, and Thomas Brox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some general notes\n",
    "* The original paper comes from back May 2015 that was the first release, so it's quite \"old\".\n",
    "* At the time it was simply the best.\n",
    "* It still is state-of-the-art at the time from some biomedical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Introduction\n",
    "* Discussing previous state-of-the-art apporaches.\n",
    "* And how CNN outperform previous methods in visual recognition task.\n",
    "* Highlighting the need for per-pixel-classification for some visual tasks (especially for biomedical images).\n",
    "* Small number of training examples for biomedical task becuase of very specific field of expertise requiered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the later part of the introduction of this research paper, the authors discussed theory behind U-net architecture:\n",
    "\n",
    "* More elegant fully convolutional network proposal.\n",
    "* Base idea is to use downsampling path for **features extraction** followed by upsampling path for **precise localization** of these features in higher resolution layers.\n",
    "* By concatenating downsampling feature maps with corresponding upsampling layers we help successive conv layers to assemble a more precise output.\n",
    "\n",
    "(don't worry this is just the theory behind, when you see the implementation or the architecture it will make much more sense.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing for mention here before we jump into the actual architecture is the *overlap tile strategy*:\n",
    "* Input size > output size.\n",
    "* Output segmentation map only contains the pixels for which the full context is available in the output image.\n",
    "* Missing context on the edge/borders of input image is extrapolated by mirroring\n",
    "![](res/overlap-tile-strategy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test that this network was designed for, there were always very little training data available, so they had to come up with very excessive data augmentations strategy, another challenge that they were facing was working on more accurate separation of touching objects, just because when you have a lot of cells, many og them were touching each other, and it's easy for segmentation network to basically merge those cells, so they had to come up with a solution to penalize the network for doing so and to focus more on drawing those separation borders between cells. My intuition is that this idea comes after making a good error analysis, so maybe for our purpose we need to omit that part of the loss function, its looks quite specific-domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
